#!/usr/bin/env python3.6

import argparse
import subprocess
import sys
import zipfile
from pathlib import Path

import yaml
import pandas as pd
import tqdm

from knock_knock import experiment, table, target_info

def check_blastn():
    no_blastn = False

    try:
        output = subprocess.check_output(['blastn', '-version'])
        if b'2.7.1' not in output:
            no_blastn = True
    except:
        no_blastn = True

    if no_blastn:
        print('blastn 2.7.1 is required and couldn\'t be found')
        sys.exit(0)

def check_parallel():
    no_parallel = False

    try:
        output = subprocess.check_output(['parallel', '--version'])
        if not output.startswith(b'GNU parallel'):
            no_parallel = True
    except:
        no_parallel = True

    if no_parallel:
        print('GNU parallel is required and couldn\'t be found')
        sys.exit(0)

def parallel(args):
    check_parallel()

    if args.group:
        args.conditions['group'] = args.group

    exps = experiment.get_all_experiments(args.base_dir, args.conditions)

    if len(exps) == 0:
        print('No experiments satify conditions:')
        print(args.conditions)
        sys.exit(0)

    parallel_command = [
        'parallel',
        '-n', '3', 
        '--bar',
        '--max-procs', str(args.max_procs),
        'knock_knock',
        '--base_dir', str(args.base_dir),
        'process', ':::',
    ]

    arg_tuples = [(exp.group, exp.name, '0') for exp in exps]
    for t in sorted(arg_tuples):
        parallel_command.extend(t)

    subprocess.check_call(parallel_command)

def process(args):
    check_blastn()

    data_dir = Path(args.base_dir) / 'data' / args.group
    sample_sheet_fn = data_dir / 'sample_sheet.yaml'
    sample_sheet = yaml.safe_load(sample_sheet_fn.read_text())

    if args.experiment in sample_sheet:
        description = sample_sheet[args.experiment]

        if description.get('platform') == 'pacbio':
            exp_class = experiment.PacbioExperiment
        elif description.get('platform') == 'illumina':
            exp_class = experiment.IlluminaExperiment
        else:
            raise ValueError(description)
    else:
        raise ValueError(args.experiment)

    exp = exp_class(args.base_dir, args.group, args.experiment, description, args.progress)

    exp.process(args.stage)

def make_tables(args):
    if args.group:
        args.conditions['group'] = args.group

    fns_to_zip = []

    results_dir = args.base_dir / 'results'
    html_fn = (results_dir / args.file_name_prefix).with_suffix('.html')
    table.generate_html(args.base_dir, html_fn, args.conditions, show_subcategories=False)
    fns_to_zip.append(html_fn)

    html_fn = (results_dir / f'{args.file_name_prefix}_with_subcategories').with_suffix('.html')
    table.generate_html(args.base_dir, html_fn, args.conditions, show_subcategories=True)
    fns_to_zip.append(html_fn)

    csv_fn = (results_dir / args.file_name_prefix).with_suffix('.csv')
    df = table.load_counts(args.base_dir, args.conditions)
    df.to_csv(csv_fn)

    exps = experiment.get_all_experiments(args.base_dir, args.conditions)

    exps_missing_files = set()

    for exp in exps:
        def add_fn(fn):
            if not fn.exists():
                exps_missing_files.add((exp.group, exp.name))
            else:
                fns_to_zip.append(fn)
        
        def add_dir(dn):
            if not dn.exists():
                exps_missing_files.add((exp.group, exp.name))
            else:
                for fn in dn.iterdir():
                    add_fn(fn)

        add_fn(exp.fns['outcome_browser'])

        for outcome in exp.outcomes:
            outcome_fns = exp.outcome_fns(outcome)
            add_fn(outcome_fns['diagrams_html'])
            add_fn(outcome_fns['first_example'])
            add_dir(outcome_fns['length_ranges_dir'])

        categories = set(c for c, s in exp.outcomes)
        for category in categories:
            outcome_fns = exp.outcome_fns(category)
            add_fn(outcome_fns['diagrams_html'])
            add_fn(outcome_fns['first_example'])

    if exps_missing_files:
        print(f'Warning: {len(exps_missing_files)} experiment(s) are missing output files:')
        for group, exp_name in sorted(exps_missing_files):
            print(f'\t{group} {exp_name}')

    zip_fn = (results_dir / args.file_name_prefix).with_suffix('.zip')
    description = 'Zipping table files'
    with zipfile.ZipFile(zip_fn, mode='w', compression=zipfile.ZIP_DEFLATED) as zip_fh:
        for fn in tqdm.tqdm(fns_to_zip, desc=description):
            zip_fh.write(fn, arcname=fn.relative_to(results_dir))

def build_targets(args):
    target_info.build_target_infos_from_csv(args.base_dir)

parser = argparse.ArgumentParser()
subparsers = parser.add_subparsers()

parser_process = subparsers.add_parser('process')
parser_process.add_argument('group')
parser_process.add_argument('experiment')
parser_process.add_argument('stage', type=int, choices=[0, 1])
parser_process.add_argument('--progress', const=tqdm.tqdm, action='store_const')
parser_process.set_defaults(func=process)

parser_parallel = subparsers.add_parser('parallel')
parser_parallel.add_argument('max_procs', type=int)
parser_parallel.add_argument('--group')
parser_parallel.add_argument('--conditions', type=yaml.safe_load, default={})
parser_parallel.set_defaults(func=parallel)

parser_table = subparsers.add_parser('table')
parser_table.add_argument('file_name_prefix')
parser_table.add_argument('--group')
parser_table.add_argument('--conditions', type=yaml.safe_load, default={})
parser_table.set_defaults(func=make_tables)

parser_targets = subparsers.add_parser('build_targets')
parser_targets.set_defaults(func=build_targets)

parser.add_argument('--base_dir', type=Path, required=True)
args = parser.parse_args()
args.func(args)
